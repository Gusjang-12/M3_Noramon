{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/ML/Python-for-Machine-Learning/00_Case_Study/Car_Data/Cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8128, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.replace(['First Owner', 'Second Owner', 'Third Owner',\n",
    "       'Fourth & Above Owner', 'Test Drive Car'], [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[df1[\"fuel\"].str.contains('CNG|LPG')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['mileage'] = df2['mileage'].str.extract('(\\d+\\.\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['engine'] = df2['engine'].str.extract('(\\d+)').astype(float)\n",
    "df2['max_power'] = df2['max_power'].str.extract('(\\d+\\.?\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(['torque'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"name\"] = df3[\"name\"].str.split().str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop(df3[df3['owner'] == 5].index, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(16.11809565095832)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['selling_price_log'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10.308919326755392)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['selling_price_log'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['selling_price_log'] = np.log(df3['selling_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [10.11, 11.61, 13.11, 14.61, df3['selling_price_log'].max()]\n",
    "labels = [0, 1, 2 ,3]\n",
    "\n",
    "df3['price_category'] = pd.cut(df3['selling_price_log'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   selling_price_log price_category\n",
      "0          13.017003              1\n",
      "1          12.821258              1\n",
      "2          11.970350              1\n",
      "3          12.323856              1\n",
      "4          11.775290              1\n"
     ]
    }
   ],
   "source": [
    "print(df3[['selling_price_log', 'price_category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>price_category</th>\n",
       "      <th>selling_price_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.017003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>2</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.821258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>3</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.970350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.323856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>88.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.775290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  year  selling_price  km_driven    fuel seller_type transmission  \\\n",
       "0   Maruti  2014         450000     145500  Diesel  Individual       Manual   \n",
       "1    Skoda  2014         370000     120000  Diesel  Individual       Manual   \n",
       "2    Honda  2006         158000     140000  Petrol  Individual       Manual   \n",
       "3  Hyundai  2010         225000     127000  Diesel  Individual       Manual   \n",
       "4   Maruti  2007         130000     120000  Petrol  Individual       Manual   \n",
       "\n",
       "   owner  mileage  engine  max_power  seats price_category  selling_price_log  \n",
       "0      1    23.40  1248.0      74.00    5.0              2          13.017003  \n",
       "1      2    21.14  1498.0     103.52    5.0              1          12.821258  \n",
       "2      3    17.70  1497.0      78.00    5.0              1          11.970350  \n",
       "3      1    23.00  1396.0      90.00    5.0              1          12.323856  \n",
       "4      1    16.10  1298.0      88.20    5.0              1          11.775290  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df3[['year','max_power' , 'engine','km_driven']]\n",
    "y_1 = df3[\"price_category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: price_category, dtype: category\n",
       "Categories (4, int64): [0 < 1 < 2 < 3]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.head()\n",
    "y_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_1train, X_1test, y_1train, y_1test = train_test_split(X_1, y_1, test_size = 0.3, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1train['year'].fillna(X_1train['year'].median(), inplace=True)\n",
    "X_1train['max_power'].fillna(X_1train['max_power'].median(), inplace=True)\n",
    "#X_1train['mileage'].fillna(X_1train['mileage'].median(), inplace=True)\n",
    "X_1train['engine'].fillna(X_1train['engine'].median(), inplace=True)\n",
    "X_1train['km_driven'].fillna(X_1train['km_driven'].median(), inplace=True)\n",
    "#X_1train['seats'].fillna(X_1train['seats'].median(), inplace=True)\n",
    "X_1test['year'].fillna(X_1test['year'].median(), inplace=True)\n",
    "X_1test['max_power'].fillna(X_1test['max_power'].median(), inplace=True)\n",
    "#X_1test['mileage'].fillna(X_1test['mileage'].median(), inplace=True)\n",
    "X_1test['engine'].fillna(X_1test['engine'].median(), inplace=True)\n",
    "X_1test['km_driven'].fillna(X_1test['km_driven'].median(), inplace=True)\n",
    "#X_1test['seats'].fillna(X_1test['seats'].median(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>max_power</th>\n",
       "      <th>engine</th>\n",
       "      <th>km_driven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>2010</td>\n",
       "      <td>69.00</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>2002</td>\n",
       "      <td>37.00</td>\n",
       "      <td>796.0</td>\n",
       "      <td>52365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>2013</td>\n",
       "      <td>88.73</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>2014</td>\n",
       "      <td>67.06</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>31000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>2018</td>\n",
       "      <td>98.97</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>35278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>2016</td>\n",
       "      <td>108.60</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>2011</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>2016</td>\n",
       "      <td>88.70</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>2011</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>2016</td>\n",
       "      <td>74.00</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2014</td>\n",
       "      <td>100.60</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2010</td>\n",
       "      <td>177.60</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>2010</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>2018</td>\n",
       "      <td>81.80</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>69779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>2019</td>\n",
       "      <td>81.83</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2011</td>\n",
       "      <td>120.00</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>1999</td>\n",
       "      <td>68.00</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>2017</td>\n",
       "      <td>126.20</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>2014</td>\n",
       "      <td>83.80</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>2015</td>\n",
       "      <td>74.00</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  max_power  engine  km_driven\n",
       "6801  2010      69.00  1396.0     175000\n",
       "2459  2002      37.00   796.0      52365\n",
       "7083  2013      88.73  1496.0     100000\n",
       "2526  2014      67.06  1364.0      31000\n",
       "3586  2018      98.97  1499.0      35278\n",
       "1675  2016     108.60  1498.0      60000\n",
       "5193  2011      80.00  1197.0     220000\n",
       "3341  2016      88.70  1199.0      41000\n",
       "7839  2011     102.00  2494.0      60000\n",
       "1481  2016      74.00  1248.0      80000\n",
       "2155  2014     100.60  2494.0     100000\n",
       "4999  2010     177.60  2354.0      74000\n",
       "7068  2010      90.00  1368.0     100000\n",
       "4332  2018      81.80  1197.0      69779\n",
       "6261  2019      81.83  1197.0       9400\n",
       "1902  2011     120.00  2179.0     150000\n",
       "4253  1999      68.00  1998.0     100000\n",
       "828   2017     126.20  1582.0      35000\n",
       "5641  2014      83.80  1461.0      90000\n",
       "5078  2015      74.00  1248.0      70000"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5619, 5)\n",
      "(5619,)\n",
      "(2409, 5)\n",
      "(2409,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1train.shape)\n",
    "print(y_1train.shape)\n",
    "print(X_1test.shape)\n",
    "print(y_1test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "#Step 1: Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_1train)\n",
    "#X_test = scaler.transform(y_1test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)  #add intercept\n",
    "intercept = np.ones((X_1test.shape[0], 1))  # สร้างคอลัมน์ที่มีค่า 1\n",
    "X_1test = np.concatenate((intercept, X_1test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(set(y_1train))  # จำนวนคลาส\n",
    "m = X_train.shape[0]  # จำนวนตัวอย่าง\n",
    "n = X_train.shape[1]  # จำนวนฟีเจอร์\n",
    "\n",
    "Y_train_encoded = np.zeros((m, k))  # สร้างอาเรย์ขนาด (m, k)\n",
    "\n",
    "for each_class in range(k):\n",
    "    cond = (y_1train == each_class)  # Boolean mask\n",
    "    Y_train_encoded[cond, each_class] = 1  # กำหนดค่าที่ตรงกันเป็น 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(set(y_1test))\n",
    "m = X_1test.shape[0]  # จำนวนตัวอย่าง\n",
    "n = X_1test.shape[1]\n",
    "Y_test_encoded = np.zeros((m, k))  # สร้างอาเรย์ขนาด (m, k)\n",
    "\n",
    "\n",
    "for each_class in range(k):\n",
    "    cond = (y_1test == each_class)  # Boolean mask\n",
    "    Y_test_encoded[cond, each_class] = 1  # กำหนดค่าที่ตรงกันเป็น 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, k, n, method, alpha = 0.001, max_iter=50000 , lambda_=0.0, use_penalty=False):\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.method = method\n",
    "        self.lambda_ = lambda_\n",
    "        self.use_penalty = use_penalty \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.W = np.random.rand(self.n, self.k)\n",
    "        self.losses = []\n",
    "        \n",
    "        if self.method == \"batch\":\n",
    "            start_time = time.time()\n",
    "            for i in range(self.max_iter):\n",
    "                loss, grad =  self.gradient(X, Y)\n",
    "                self.losses.append(loss)\n",
    "                self.W = self.W - self.alpha * grad\n",
    "                if i % 2000 == 0:\n",
    "                    print(f\"Loss at iteration {i}\", loss)\n",
    "            print(f\"time taken: {time.time() - start_time}\")\n",
    "            \n",
    "        elif self.method == \"minibatch\":\n",
    "            start_time = time.time()\n",
    "            batch_size = int(0.3 * X.shape[0])\n",
    "            for i in range(self.max_iter):\n",
    "                ix = np.random.randint(0, X.shape[0]) #<----with replacement\n",
    "                batch_X = X[ix:ix+batch_size]\n",
    "                batch_Y = Y[ix:ix+batch_size]\n",
    "                loss, grad = self.gradient(batch_X, batch_Y)\n",
    "                self.losses.append(loss)\n",
    "                self.W = self.W - self.alpha * grad\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"Loss at iteration {i}\", loss)\n",
    "            print(f\"time taken: {time.time() - start_time}\")\n",
    "            \n",
    "        elif self.method == \"sto\":\n",
    "            start_time = time.time()\n",
    "            list_of_used_ix = []\n",
    "            for i in range(self.max_iter):\n",
    "                idx = np.random.randint(X.shape[0])\n",
    "                while i in list_of_used_ix:\n",
    "                    idx = np.random.randint(X.shape[0])\n",
    "                X_train = X[idx, :].reshape(1, -1)\n",
    "                Y_train = Y[idx]\n",
    "                loss, grad = self.gradient(X_train, Y_train)\n",
    "                self.losses.append(loss)\n",
    "                self.W = self.W - self.alpha * grad\n",
    "                \n",
    "                list_of_used_ix.append(i)\n",
    "                if len(list_of_used_ix) == X.shape[0]:\n",
    "                    list_of_used_ix = []\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"Loss at iteration {i}\", loss)\n",
    "            print(f\"time taken: {time.time() - start_time}\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('Method must be one of the followings: \"batch\", \"minibatch\" or \"sto\".')\n",
    "        \n",
    "        \n",
    "    def gradient(self, X, Y):\n",
    "        m = X.shape[0]\n",
    "        h = self.h_theta(X, self.W)\n",
    "        loss = - np.sum(Y*np.log(h)) / m\n",
    "        error = h - Y\n",
    "        grad = self.softmax_grad(X, error)\n",
    "\n",
    "        if self.use_penalty:\n",
    "            reg_term = self.lambda_ * self.W\n",
    "            reg_term[0, :] = 0\n",
    "            loss += self.lambda_ * np.sum(np.square(self.W[1:, :])) / 2\n",
    "            grad += reg_term\n",
    "        return loss, grad\n",
    "\n",
    "    def softmax(self, theta_t_x):\n",
    "        return np.exp(theta_t_x) / np.sum(np.exp(theta_t_x), axis=1, keepdims=True)\n",
    "\n",
    "    def softmax_grad(self, X, error):\n",
    "        return  X.T @ error\n",
    "\n",
    "    def h_theta(self, X, W):\n",
    "        '''\n",
    "        Input:\n",
    "            X shape: (m, n)\n",
    "            w shape: (n, k)\n",
    "        Returns:\n",
    "            yhat shape: (m, k)\n",
    "        '''\n",
    "        return self.softmax(X @ W)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.argmax(self.h_theta(X_test, self.W), axis=1)\n",
    "    \n",
    "    def plot(self):\n",
    "        plt.plot(np.arange(len(self.losses)) , self.losses, label = \"Train Losses\")\n",
    "        plt.title(\"Losses\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"losses\")\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoPenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l # lambda value\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.abs(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * np.sign(theta)\n",
    "\n",
    "\n",
    "class RidgePenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.square(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * 2 * theta\n",
    "\n",
    "class Ridge(LogisticRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = RidgePenalty(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 1.49745426980261\n",
      "Loss at iteration 500 0.3898976785334476\n",
      "Loss at iteration 1000 0.40652359711840674\n",
      "Loss at iteration 1500 0.4731383746803387\n",
      "Loss at iteration 2000 0.3922191284291691\n",
      "Loss at iteration 2500 0.3967517044548257\n",
      "Loss at iteration 3000 0.40373649256681277\n",
      "Loss at iteration 3500 0.3975045600289264\n",
      "Loss at iteration 4000 0.38623328677960106\n",
      "Loss at iteration 4500 0.3916127236713753\n",
      "Loss at iteration 5000 0.40014576429306525\n",
      "Loss at iteration 5500 0.4045186024814909\n",
      "Loss at iteration 6000 0.3893823340361618\n",
      "Loss at iteration 6500 0.39836742531693736\n",
      "Loss at iteration 7000 0.39542332827952353\n",
      "Loss at iteration 7500 0.40299734616820104\n",
      "Loss at iteration 8000 0.4009740722567407\n",
      "Loss at iteration 8500 0.39358541744189945\n",
      "Loss at iteration 9000 0.40525362459743863\n",
      "Loss at iteration 9500 0.4038121397240966\n",
      "Loss at iteration 10000 0.40706682566972996\n",
      "Loss at iteration 10500 0.4051663900440193\n",
      "Loss at iteration 11000 0.3916464866396324\n",
      "Loss at iteration 11500 0.3939526001945311\n",
      "Loss at iteration 12000 0.3887553947348613\n",
      "Loss at iteration 12500 0.39016996198845183\n",
      "Loss at iteration 13000 0.39917828677312134\n",
      "Loss at iteration 13500 0.3976239664000591\n",
      "Loss at iteration 14000 0.3819118011349772\n",
      "Loss at iteration 14500 0.39010335455724865\n",
      "Loss at iteration 15000 0.44369815619178243\n",
      "Loss at iteration 15500 0.39023582858250394\n",
      "Loss at iteration 16000 0.3986386132897402\n",
      "Loss at iteration 16500 0.4633663793245287\n",
      "Loss at iteration 17000 0.38845407785792474\n",
      "Loss at iteration 17500 0.3887556525640615\n",
      "Loss at iteration 18000 0.3995809679179954\n",
      "Loss at iteration 18500 0.3861497143010178\n",
      "Loss at iteration 19000 0.3951308617772429\n",
      "Loss at iteration 19500 0.3916951013082939\n",
      "Loss at iteration 20000 0.39471990706171467\n",
      "Loss at iteration 20500 0.4058845342505094\n",
      "Loss at iteration 21000 0.3953549451768805\n",
      "Loss at iteration 21500 0.4019024443338618\n",
      "Loss at iteration 22000 0.388681171927823\n",
      "Loss at iteration 22500 0.38870351073831233\n",
      "Loss at iteration 23000 0.4046762845696419\n",
      "Loss at iteration 23500 0.402059018806325\n",
      "Loss at iteration 24000 0.3916769732915203\n",
      "Loss at iteration 24500 0.4062332419079827\n",
      "Loss at iteration 25000 0.5105844316578474\n",
      "Loss at iteration 25500 0.4374677785288026\n",
      "Loss at iteration 26000 0.3811137342375807\n",
      "Loss at iteration 26500 0.3898489855141824\n",
      "Loss at iteration 27000 0.3946095243899608\n",
      "Loss at iteration 27500 0.38984154913826735\n",
      "Loss at iteration 28000 0.3881603790935061\n",
      "Loss at iteration 28500 0.3990168572624694\n",
      "Loss at iteration 29000 0.4017162296730937\n",
      "Loss at iteration 29500 0.3870775914552782\n",
      "Loss at iteration 30000 0.40812079371582183\n",
      "Loss at iteration 30500 0.3998386176952191\n",
      "Loss at iteration 31000 0.39921025520370124\n",
      "Loss at iteration 31500 0.39166109479443667\n",
      "Loss at iteration 32000 0.40021192191032856\n",
      "Loss at iteration 32500 0.39918932883138425\n",
      "Loss at iteration 33000 0.38828024185278814\n",
      "Loss at iteration 33500 0.39625462778817944\n",
      "Loss at iteration 34000 0.3858999271394563\n",
      "Loss at iteration 34500 0.4046754542819758\n",
      "Loss at iteration 35000 0.38972276170856984\n",
      "Loss at iteration 35500 0.3876103459272494\n",
      "Loss at iteration 36000 0.39474805665058293\n",
      "Loss at iteration 36500 0.3930330527356563\n",
      "Loss at iteration 37000 0.38868325003619675\n",
      "Loss at iteration 37500 0.40313363612025305\n",
      "Loss at iteration 38000 0.3955481787795583\n",
      "Loss at iteration 38500 0.3992593480144995\n",
      "Loss at iteration 39000 0.38732595852575663\n",
      "Loss at iteration 39500 0.39016773567915425\n",
      "Loss at iteration 40000 0.3981041403950962\n",
      "Loss at iteration 40500 0.4027506626237266\n",
      "Loss at iteration 41000 0.388094076702616\n",
      "Loss at iteration 41500 0.3926007999362573\n",
      "Loss at iteration 42000 0.38286772025723026\n",
      "Loss at iteration 42500 0.38022467384984837\n",
      "Loss at iteration 43000 0.3807623651549377\n",
      "Loss at iteration 43500 0.38108054190005525\n",
      "Loss at iteration 44000 0.4052400788330757\n",
      "Loss at iteration 44500 0.3897624069054968\n",
      "Loss at iteration 45000 0.39113512529920746\n",
      "Loss at iteration 45500 0.4034731113006118\n",
      "Loss at iteration 46000 0.3929697430124625\n",
      "Loss at iteration 46500 0.3868864241223702\n",
      "Loss at iteration 47000 0.3890180993644135\n",
      "Loss at iteration 47500 0.40612472171488667\n",
      "Loss at iteration 48000 0.40733986871000255\n",
      "Loss at iteration 48500 0.3914175093869055\n",
      "Loss at iteration 49000 0.39076652454660643\n",
      "Loss at iteration 49500 0.38997682968437786\n",
      "time taken: 6.1660475730896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = LogisticRegression(k, X_train.shape[1], \"minibatch\")\n",
    "\n",
    "model.fit(X_train, Y_train_encoded)\n",
    "#print(\"Shape of X_train:\", X_train.shape)  # ควรเป็น (2409, n_features)\n",
    "#print(\"Shape of W:\", model.W.shape)  # ควรเป็น (n_features, k)\n",
    "#print(\"Shape of X_1test:\", X_1test.shape)\n",
    "yhat = model.predict(X_1test)\n",
    "\n",
    "#model.plot()\n",
    "\n",
    "#print(\"=========Classification report=======\")\n",
    "#print(\"Report: \", classification_report(y_1test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for each class: [np.float64(0.059366754617414245), np.float64(0.13592233009708737), np.float64(0.4375), 0]\n",
      "recall :  [np.float64(0.9926470588235294), np.float64(0.012313104661389622), np.float64(0.01364522417153996), np.float64(0.0)]\n",
      "F1 :  [np.float64(0.11203319502074689), np.float64(0.02258064516129032), np.float64(0.026465028355387523), 0]\n",
      "accuracy :  0.0676629306766293\n",
      "macro_precision :  0.16\n",
      "macro_recall :  0.25\n",
      "macro_F1 :  0.04\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(yhat == y_1test)/ len(y_1test)\n",
    "num_classes = len(np.unique(y_1test))# จำนวนคลาสทั้งหมด\n",
    "precision_per_class = []\n",
    "recall_per_class = []\n",
    "f1_per_class = []\n",
    "for c in range(num_classes): #วนเช็คคลาสทั้งหมด\n",
    "    TP_c = np.sum((yhat == c) & (y_1test == c))#ถ้าหา C = 1 ใน yhat และเ y_test ก็เป็น 1 \n",
    "    FP_c = np.sum((yhat== c) & (y_1test != c)) # ถ้าหา C = 1 ใน yhat และ y_test ไม่เป็น 1 \n",
    "    FN_c = np.sum((yhat != c) & (y_1test == c))\n",
    "    \n",
    "    precision_c = TP_c / (TP_c + FP_c) if (TP_c + FP_c) > 0 else 0\n",
    "    recall = TP_c/(TP_c + FN_c) if (TP_c + FN_c) > 0 else 0\n",
    "    f1 = (2*precision_c*recall)/(precision_c + recall) if (precision_c + recall) > 0 else 0\n",
    "    precision_per_class.append(precision_c)\n",
    "    recall_per_class.append(recall)\n",
    "    f1_per_class.append(f1)\n",
    "    \n",
    "print(\"Precision for each class:\", precision_per_class)\n",
    "print(\"recall : \" , recall_per_class)   \n",
    "print(\"F1 : \", f1_per_class)\n",
    "print(\"accuracy : \", accuracy)\n",
    "\n",
    "macro_precision = sum(precision_per_class)/4\n",
    "macro_recall = sum(recall_per_class)/4\n",
    "macro_F1 = sum(f1_per_class)/4\n",
    "\n",
    "print(\"macro_precision : \", '{:.2f}'.format(macro_precision))\n",
    "print(\"macro_recall : \", '{:.2f}'.format(macro_recall))\n",
    "print(\"macro_F1 : \", '{:.2f}'.format(macro_F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_precision: 0.14\n",
      "weighted_recall :  0.20\n",
      "Fweighted_F1 :  0.03\n"
     ]
    }
   ],
   "source": [
    "W = np.array([0.2, 0.3, 0.2, 0.3])\n",
    "weighted_precision = np.sum(W*precision_per_class)\n",
    "weighted_recall = np.sum(W*recall_per_class)\n",
    "weighted_F1 = np.sum(W*f1_per_class)\n",
    "\n",
    "print(\"weighted_precision:\", '{:.2f}'.format(weighted_precision))\n",
    "print(\"weighted_recall : \" , '{:.2f}'.format(weighted_recall))   \n",
    "print(\"Fweighted_F1 : \", '{:.2f}'.format(weighted_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Classification report=======\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.99      0.11       136\n",
      "           1       0.14      0.01      0.02      1137\n",
      "           2       0.44      0.01      0.03      1026\n",
      "           3       0.00      0.00      0.00       110\n",
      "\n",
      "    accuracy                           0.07      2409\n",
      "   macro avg       0.16      0.25      0.04      2409\n",
      "weighted avg       0.25      0.07      0.03      2409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=========Classification report=======\")\n",
    "print(\"Report: \", classification_report(y_1test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoPenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l # lambda value\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.abs(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * np.sign(theta)\n",
    "\n",
    "\n",
    "class RidgePenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.square(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * 2 * theta\n",
    "\n",
    "class Ridge(LogisticRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = RidgePenalty(l)\n",
    "        #super().__init__(k, n, method, alpha = 0.001, max_iter=50000, regularization=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5619, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 3.3321947903191655\n",
      "Loss at iteration 2000 nan\n",
      "Loss at iteration 4000 nan\n",
      "Loss at iteration 6000 nan\n",
      "Loss at iteration 8000 nan\n",
      "time taken: 4.437903881072998\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHp0lEQVR4nO3dB3iUxRbG8ZPeEwghoYYOAaQ3KRcLSBEV7CgoKMK1oKKI7aoIFhSvXgsKWLGigB1FpYmC9Ca9Q0JJQk0hpO99zuCuCYKEmOTbfPv/Pc+67cvubHbNvsycmfFyOBwOAQAAsClvqxsAAABQmgg7AADA1gg7AADA1gg7AADA1gg7AADA1gg7AADA1gg7AADA1gg7AADA1gg7AADA1gg7AADA1gg7ACwxZcoU8fLykhUrVljdFAA2R9gBAAC2RtgBAAC2RtgB4LZWr14tvXv3lvDwcAkNDZVu3brJkiVLCh2Tk5MjY8aMkQYNGkhgYKBUqlRJunTpIrNnz3Ydk5iYKLfccovUqFFDAgICpGrVqtK3b1/ZvXt3oceaNWuW/Otf/5KQkBAJCwuTPn36yIYNGwodU9THAuA+fK1uAACcjoYMDR4adB588EHx8/OTyZMny4UXXigLFiyQDh06mOOefPJJGTdunNx2223Svn17SU1NNXVAq1atkksuucQcc/XVV5vHu/vuu6V27dqSnJxswlB8fLy5rj788EMZNGiQ9OzZU55//nnJyMiQiRMnmuCkoct5XFEeC4CbcQCABd577z2H/glavnz5ae/v16+fw9/f37Fjxw7Xbfv373eEhYU5unbt6rqtRYsWjj59+pzxeY4ePWqe54UXXjjjMWlpaY4KFSo4hg4dWuj2xMRER0REhOv2ojwWAPfDMBYAt5OXlyc//fST9OvXT+rWreu6XYeMbrzxRlm4cKHpwVEVKlQwPS3btm077WMFBQWJv7+//Pzzz3L06NHTHqM9M8eOHZMbbrhBDh065Dr5+PiYHqT58+cX+bEAuB/CDgC3c/DgQTOM1KhRo7/c17hxY8nPz5eEhARzfezYsSaoNGzYUJo1ayajRo2S33//3XW81tXosJTW48TExEjXrl1l/PjxpvbGyRmULr74YqlcuXKhk4YuHaoq6mMBcD+EHQDlmgaOHTt2yLvvvivnnXeevP3229K6dWtz7jRixAjZunWrqe3RIubHH3/chCatxVEanpx1O9rLc+rp66+/LvJjAXBDVo+jAfBMf1ezk5ub6wgODnZcd911f7nv9ttvd3h7eztSUlLOWH/TqlUrR/Xq1c/43Fu3bjWPP2DAAHN92rRppi0//vjjOb+OUx8LgPuhZweA29FamR49epgelYJTupOSkuSTTz4xM6R0lpY6fPhwoZ/VKer169eXrKwsc12HwzIzMwsdU69ePTO13HmMzsDSx3v22WfNVPbTDasV9bEAuB+mngOwlA4//fDDD3+5XaeU6xCSBps777xTfH19zdRzDRVaJ+PUpEkTMx29TZs2EhkZaaadz5gxQ4YPH27u1yEnXZ/nuuuuM8fq43z55ZcmOPXv398co0FHp5nfdNNNZghMb9d6HZ1O/t1330nnzp1lwoQJRXosAG7I6q4lAJ49jHWmU0JCgmPVqlWOnj17OkJDQ81Q0UUXXeT47bffCj3O008/7Wjfvr2ZOh4UFOSIi4tzPPPMM47s7Gxz/6FDhxx33XWXuT0kJMRMJe/QoYMZujrV/PnzzfPpMYGBgY569eo5Bg8e7FixYsU5PxYA9+Gl/7E6cAEAAJQWanYAAICtEXYAAICtEXYAAICtEXYAAICtEXYAAICtEXYAAICtsajgH/vi7N+/36yC6uXlZXVzAABAEejqOWlpaVKtWjXx9j5z/w1hR8QEnZo1a1rdDAAAUAwJCQlSo0aNM95P2BExPTrOX5Zzvx0AAODeUlNTTWeF83v8TAg7Iq6hKw06hB0AAMqXs5WgUKAMAABsjbADAABsjbADAABsjZqdc5ienp2dbXUz4Ab8/f3/doojAMC9EHaKQEPOrl27TOABNOjUqVPHhB4AgPsj7BRhwaIDBw6Ij4+Pmd7Gv+g9m3MBSv1MxMbGsgglAJQDhJ2zyM3NlYyMDLM6Y3BwsNXNgRuoXLmyCTz62fDz87O6OQCAs6Cb4izy8vLMOUMWcHJ+FpyfDQCAeyPsFBHDFXDiswAA5QthBwAA2BphB0VWu3Ztefnll61uBgAA54SwY9Nhlr87Pfnkk8V63OXLl8uwYcP+UdsuvPBCGTFixD96DAAAzgWzsWxIp0U7ffbZZ/LEE0/Ili1bXLeFhoYWmlqvhba+vr5FmoUEAEB5Q8+ODVWpUsV1ioiIML05zuubN2+WsLAwmTVrlrRp00YCAgJk4cKFsmPHDunbt6/ExMSYMNSuXTuZM2fO3w5j6eO+/fbbcuWVV5pp+Q0aNJBvvvnmH7X9888/l6ZNm5p26fO9+OKLhe5/4403zPMEBgaatl5zzTWu+2bMmCHNmjWToKAgqVSpknTv3l2OHz/uul/b2rhxY/OzcXFx5rEKLhw5fPhwqVq1qrm/Vq1aMm7cuH/0WgAA7oGenXOkPSEncqyZchzk51NiM4Eefvhh+e9//yt169aVihUrSkJCglx66aXyzDPPmKDxwQcfyOWXX256hHTxvDMZM2aMjB8/Xl544QV57bXXZMCAAbJnzx6JjIw85zatXLlSrrvuOjPMdv3118tvv/0md955pwkugwcPlhUrVsg999wjH374oXTq1EmOHDkiv/76q6s364YbbjBt0fCVlpZm7tP3S3388cemh2vChAnSqlUrWb16tQwdOlRCQkJk0KBB8uqrr5qgNm3aNPN69fehJwBA+UfYOUcadJo88aMlz71xbE8J9i+Zt2zs2LFyySWXuK5rOGnRooXr+lNPPSVffvmlCQDa43EmGkI0ZKhnn33WhIZly5ZJr169zrlNL730knTr1k0ef/xxc71hw4ayceNGE6T0eeLj4004ueyyy0zvlPa+aHBxhh1d5O+qq64ytyvt5XEaPXq06SXS+5Vu96CPPXnyZBN29LG1x6hLly4mUDofAwBQ/jGM5aHatm1b6Hp6ero88MADZpinQoUKZihr06ZNJgT8nebNm7suaxAJDw+X5OTkYrVJn69z586FbtPr27ZtM3VFGs40hGhv1E033WR6a3R1a6VBTYOSBpxrr71W3nrrLTl69Ki5T4eydJhuyJAh5nU5T08//bS5XWmYWrNmjTRq1Mj0Hv3000/Feg0AAPdDz04xhpK0h8Wq5y4pGkwK0qAze/ZsM7RVv359U/ei9TBn2+n91O0StFektDZM1d6cVatWyc8//2zCiA5L6ZCXzhLTgKbt16EvvU+H1P7zn//I0qVLXdt8aADq0KFDocfUPc9U69atzWavWsuktUo6nKY1P1oHBAAo3wg750i/zEtqKMmdLFq0yPRuaL2Ls6dn9+7dZdoG7VXSdpzaLh3OcoYSnTWmIURPOjSlIWfevHlmeErfG+0J0pMGIe0F0qG4+++/3+xttnPnTlNTdCbaK6W1QnrSoKdDcVoXVJz6IwCA+7DftzaKRetVvvjiC1OUrKFB62ZKq4fm4MGDZsioIJ0FNXLkSDMLTOuFNHAsXrzYFBQ7Z03NnDnTBJauXbuaourvv//etFGHnrQHZ+7cudKjRw+Jjo421/V5NEA5C6l1eEpnp2mIycrKMgXPOtSlYUjrhbQNWgOkO9tPnz7dzF7TMAUAKN8IOzD0y/7WW281s5yioqLkoYcektTU1FJ5rk8++cScCtKA89hjj5nZUNoro9c1fGghtfY4KQ0eGsh06CozM9MEtKlTp5qp6lrv88svv5ip8dpu7dXRguTevXubn73tttvMcJYWO48aNcoM42l9j3OBQx0i05lcWh+kvUgaujRMafABAJRvXg7n3FwPpl+O+i/+lJQUM5RRkH6pai2Hzt7R9VcAPhMA4P7f3wXxz1YAAGBrhB0AAGBrhB0AAGBrhB0AAGBrhJ0ioo4bTnwWAKB8IeychXMxu7OtJAzP4fwsOD8bAAD3xjo7Z6Er9ur6LLpAnW6NwLornk0XMdTPgn4m9LMBAHB//LU+C11NWBe303VV9uzZY3Vz4AY08MbGxprPBgDA/RF2isDf39+s1stQFpyfB3r4AKD8IOwUkX65sVouAADlD/88BQAAtkbYAQAAtmZp2MnLy5PHH3/cbKgYFBQk9erVM7tdF1zHRC/rLthaJKzHdO/e3exMXdCRI0dkwIABZhMw3Rl7yJAhkp6ebsErAgAA7sbSsPP888/LxIkTZcKECbJp0yZzffz48fLaa6+5jtHrr776qkyaNEmWLl0qISEh0rNnT7PztJMGnQ0bNsjs2bNl5syZ8ssvv8iwYcMselUAAMCdeDksXA72sssuk5iYGHnnnXdct1199dWmB+ejjz4yvTrVqlWTkSNHygMPPGDu123c9WemTJki/fv3NyGpSZMmsnz5cmnbtq055ocffpBLL71U9u7da36+pLaIBwAA7qOo39+W9ux06tRJ5s6dK1u3bjXX165dKwsXLpTevXub67q2TWJiohm6ctIX1aFDB1m8eLG5ruc6dOUMOkqP19lT2hN0OllZWeYXVPAEAADsydKp5w8//LAJGnFxcWbpfa3heeaZZ8ywlNKgo7QnpyC97rxPz6OjowvdryvbRkZGuo451bhx42TMmDGl9KoAAIA7sbRnZ9q0afLxxx/LJ598IqtWrZL3339f/vvf/5rz0vTII4+YLi/nKSEhoVSfDwAAeGjPzqhRo0zvjtbeqGbNmpktGbTnZdCgQVKlShVze1JSkpmN5aTXW7ZsaS7rMcnJyYUeNzc318zQcv78qQICAswJAADYn6U9OxkZGX9Zdl+Hs3SzRaVT0jWwaF2Pkw57aS1Ox44dzXU9P3bsmKxcudJ1zLx588xjaG0PAADwbJb27Fx++eWmRkc3VWzatKmsXr1aXnrpJbn11lvN/brR4ogRI+Tpp582e1Np+NF1eXSGVb9+/cwxjRs3ll69esnQoUPN9PScnBwZPny46S0qykwsAABgb5aGHV1PR8PLnXfeaYaiNJz8+9//NosIOj344INy/Phxs26O9uB06dLFTC0vuE+V1v1owOnWrZvpKdLp67o2DwAAgKXr7LgL1tkBAKD8KRfr7AAAAJQ2wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1wg4AALA1X6sbAACwj8ycPNmenG5O25LTZGvSycuv9G8pzWtUsLp58FCEHQDAOTuRnSc7DqbL1qQ02abB5o/z+CMZ4nD89XgNPYQdWIWwAwAoknV7U+SVudtkS1Kq7D164rShRlUI9pOG0WHSICZUGkSHSoOYMDmvWkRZNxdwIewAAM5q79EMufndpXI0I8d1W6UQf6kfHSoNY04GG+dlvd3Ly8vS9gIFEXYAAGetw/n3hytN0GlWPUL+06ex6bGpFBpgddOAIiHsAADOyOFwyKNfrpMN+1MlMsRfJt3URqpXCLK6WcA5Yeo5AOCMPli8R75YtU98vL1kwo2tCDoolwg7AIDTWrbriDw1c6O5/EjvOOlUL8rqJgHFQtgBAPzFgZQTcufHKyU33yF9W1aTIV3qWN0koNgIOwCAQrJy8+SOj1bJofRsaVw1XJ67qjmzq1CuEXYAAIU8+c0GWZNwTCKC/GTywDYS5O9jdZOAf4SwAwBw+WRpvExdliDakfPqDa0ktlKw1U0C/jHCDgDAWBV/VEZ/s95cHtWzkVzQsLLVTQJKBGEHACDJaZlyx0crJSfPIb3PqyJ3XFDP6iYBJYawAwAeLjs3X+76eJUkpWaZlZFfuLYFBcmwFcIOAHi4Z77bKMt3H5WwAF+ZfFMbCQ1gcX3YC2EHADzYjJV75f3Fe8zll/u3lLqVQ61uElDiCDsA4KHW7U0x+16pEd0bSLfGMVY3CSgVhB0A8EDbk9Pl9o9Wmnqd7o2j5Z6LG1jdJKDUMDALAB4iLTNHZv5+wAxdrdxz1NxWNypEXrq+pXh7U5AM+yLsAICN5ec7ZMnOwzJ95V6Ztf6AZObkm9s121zYKFpGX95EwgP9rG4mUKoIOwBgQwlHMkzA+XzlXtl37ITr9nqVQ+TatjXlqlbVJTo80NI2AmWFsAMANpGRnSvfr0uU6SsSZOmuI67bwwJ95fIW1eTaNjWkZc0KrKEDj0PYAYByLuVEjjw3a5N8s2a/HM/OM7dpnulSP0quaVNDejatIoF+bOYJz0XYAYByzOFwyCNf/G56dFTtSsEm4FzZuoZUrxBkdfMAt0DYAYAi0LqX1fFHTYBoFVtR3IXOrtKg4+PtJW/f3FYubFSZYSrgFIQdADhFbl6+bE5MkxW7j8iKPUfNNO0DKZnmPl9vL/n8jk7SomYFt9i88/GvT+5SftdF9eWiuGirmwS4JcIOAI+n68+sjj/2R7A5Imvij7lqX5y05yQyxF8OpmXJ3VNXy3f3dJEwC6ds6/DVo1+sl2MZOdKkargMv6i+ZW0B3B1hB4BH0iGpL1btMwFnS2Kq5DsK368zmFrHVpS2tSpKm9oVzSymnDyHXPrKrxJ/JEP+8+V6eaV/S8uGjLTtczYliZ+Pl7x0fQvx92VBfOBMCDsAPM6yXUdk4NtLJTvv5AJ7qmZkkLStFSltalWUtrUrSoPoMNObc6pXb2gl101eLN+s3S9dGkTJdW1rlnHrRRJTMuXJbzeYyyO6N5S4KuFl3gagPCHsAPAoOw+my7APV5ig868GUXJD+1gTcGKKuMCeHjuyR0MZ/8MWGf31BmkdW0HqR4dJWQ5fPfT575KWmWvqhv7dtW6ZPTdQXtHvCcBjHDmeLbdOWW7qXHRY6q2b28qlzaoWOeg43d61nlnD5kROngz/ZLVk5hSu7ylNny1PkAVbD5phqxevbS6+PvwZB86G/0sAeAQNJEM/WCG7D2dIjYpBJugUd6E93TRT62SiQv3NrK1nv98kZWHv0Qx5+ruTz/VAj4Zl2qMElGeEHQAesRnmA9PXminkWng85ZZ2Ujks4B89ZnRYoLx4XUtz+YPFe+SH9ScX9SvN1/DgjN8lPSvXFE0P6cLwFVBuws6+fftk4MCBUqlSJQkKCpJmzZrJihUrCo1PP/HEE1K1alVzf/fu3WXbtm2FHuPIkSMyYMAACQ8PlwoVKsiQIUMkPT3dglcDwB29OHuLWXxP18iZPLBNifWIXNCwsqtmRutoCm64WdI+XrpHfttxWAL9vOWFa1uctngagBuGnaNHj0rnzp3Fz89PZs2aJRs3bpQXX3xRKlb8c3XS8ePHy6uvviqTJk2SpUuXSkhIiPTs2VMyM08u8KU06GzYsEFmz54tM2fOlF9++UWGDRtm0asC4E6mLU+Q1+fvMJfHXdVMOtWPKtHHH9mjkSkU1v2p7p262ixIWNL2HD4uz36/2Vx+uFec1IkKKfHnAOzMy6FdJxZ5+OGHZdGiRfLrr7+e9n5tWrVq1WTkyJHywAMPmNtSUlIkJiZGpkyZIv3795dNmzZJkyZNZPny5dK2bVtzzA8//CCXXnqp7N271/z82aSmpkpERIR5bO0dAmAPC7cdksHvLZPcfIfcfXF9E0xKQ/zhDOnz6q+SlpVb4s+jw1f931wiy3YfkY51K8nHt3UwNUMApMjf35b27HzzzTcmoFx77bUSHR0trVq1krfeest1/65duyQxMdEMXTnpi+rQoYMsXrzYXNdzHbpyBh2lx3t7e5ueoNPJysoyv6CCJwD2sjUpTe74aKUJOn1bVpP7L2lYas8VWylYnr2qmbk8Yf52+W3HoRJ77Pd+222CToi/j4y/pjlBBygGS8POzp07ZeLEidKgQQP58ccf5Y477pB77rlH3n//fXO/Bh2lPTkF6XXnfXquQakgX19fiYyMdB1zqnHjxpnQ5DzVrFn2i4IBKN09o255b7npaWlXu6IJCaW90vHlLapJ/3Y1RfvKR3y6Rg6nZ/3jx9xxMF3G/3By+OrRPo2lZmRwCbQU8DyWhp38/Hxp3bq1PPvss6ZXR+tshg4daupzStMjjzxiurycp4SEhFJ9PgBl50R2ngx9f4UpFtbaljdvaisBvsWbYn6uRl/eVOpHh0pyWpaZ/aVDUMWV98cMsqzck4sf3tg+tkTbCngSS8OOzrDSepuCGjduLPHx8eZylSpVzHlSUlKhY/S68z49T05OLnR/bm6umaHlPOZUAQEBZmyv4AlA+acBYcRnq2Xt3hSpGOwn7w1uJxVD/Mvs+YP8fWTCja3Mgn/ztxyUdxftKvZjvfnLTrM5aViArzx/den3TAF2ZmnY0ZlYW7ZsKXTb1q1bpVatWuZynTp1TGCZO3eu636tr9FanI4dO5rren7s2DFZuXKl65h58+aZXiOt7QHgOcZ9v0l+3JAk/j7e8ubNbaW2BbOWdJ+qJy47+Y+453/YLOv2phSr3uh/s7eay09c3kSqVQgq8XYCnsTSvbHuu+8+6dSpkxnGuu6662TZsmXy5ptvmpPSf8mMGDFCnn76aVPXo+Hn8ccfNzOs+vXr5+oJ6tWrl2v4KycnR4YPH25mahVlJhYAe/hw8W55e+HJnpQXrm0u7WpHWtaWAR1iZdH2QzJrfaIMn7pKZt7dRcIC/cwM08ycfLMw4HE9Zet5nrnsvE3PZ6zca/bu6hYXLde0qWHZ6wDswtKp50rXxdEaGl0oUMPM/fffb4KLkzZv9OjRJgBpD06XLl3kjTfekIYN/5xZoUNWGnC+/fZbMwvr6quvNmvzhIaGFqkNTD0HSo/+P1zaQzDzNyfLkPeXi5bI6DYKwy9uIFZLyciRS1/91dQORQT5Sb7DIRnZeWaorSj0Z2bf11Wiz3HfLsCTpBbx+9vysOMOCDtAydKZSLpi8Zer98mG/Sny7JXN5Nq2pTPrUWcs9Z2wyPSIXNe2hlvVt6zcc8SskZOT99c/s8H+PhIS4CuhAb4SEuAjIf7Oy74SHuQrN7avJU2q8fcIKInvb0uHsQDYR0Z2rszemCRfrd4nv2w7VKgH49Ev15n6mZIeWkrLzJFhH6wwQad97Uh5ul8ztwk6qk2tSJk38kI5mpFdINj4SrCfD+vlAGWIsAN4IA0iv247aM7rVg6VmhWDxNfn3Ocr6NYIul+TBpwfNiSaYRqn5jUipF/L6rJ89xFTu3L7hyvlm7u7SPUSKrbVad0jp62VHQePS5XwQHl9QGszC8rd6No4rI8DWIuwA3iYnLx8GfHZGvnu9wOu2/x8vKRWpRCpGxViwk/dyiFSr7JeD/3L1G0d+V6/L9UMUX2zdr8cKrB4XmxksPRrWU36tqou9SqfrJnr376m7DmcIRsPpJr1b2bc0VGC/f/5n543ft4uP208OfNq4sDW/3gXcwD2Rc0ONTvwINm5+XL31FVmerYGHA0kuw4dNwvXnYmuV1PvjwCkwWfOxiTTm1Lw/suaV5N+rapL69gKpx1G0iLdK15bKIePZ0ufZlXNWjT/ZLhp/pZkuXXKcrNa8fNXN5Pr27HgHuCJUilQLjrCDjxBVm6e3PnRKpm7OdkM90wa2Foujosxw0H7U07IzoPHZefBdNl5SM+Pm8LfAymZp32sAF9vuaRJjFzZqrp0bVhZ/IowBKbDWTe+dbJY95/MmNp96LhcMWGhpGbmyo0dYk3xMwDPlErYKTrCDuwuMydPhn24Un7ZetAElbdubmtCSlGKjk0IMgEoXZJSM03Rbc+mMWbdmHM1dVm8PPLFOnP5zZvaSI+mp1/l/Ex0HZqr3vhNtiSlmV6kqcPOL7OtIAC4H2ZjAXAFltveX2EKiYP8fOSdQW2lU/2oIv2s1tacVz3CnErCDe1jZfOBVHl/8R6577M18sWdnaVRlbAi/az+u+zBz383QUfrcyYObEPQAVAk7jd1AfBgOqS0NuGYqaMpCTole/B7y03QCfH3kfdvbV/koFNaHrusiXSsW0mOZ+fJbR8sl6PHs4u8V5QWVft6e8nEAa0lhsX2ABQRPTuAG0hOzZTpK/fKtBUJZuaS0kLee7s3kIYxRev5OFVqZo4MfneZrPpjM8kpt7aXNrUqitW0vueNAa3litcXSsKRE3Lnx6vkgyHt/7buR6fJ6z5TavQVTaWthVtBACh/qNmhZgcW0TVuFmxNlk+XJZiiYecifLqyrnO9Gp2wpKFnRPcGUj867Jy2Krj5vWWmlyg80Fc+uq2DNK9RQdzJlsQ0ueqNRaaHZ1DHWjKm73mnPS7hSIZcPmGhHMvIkWvb1JDx17jPCskArEWB8jkg7KAs7T2aIdOWJ5ienIKznbTX5fp2NeWy5lUl/kiGvDJnm1mMT+l3+xUtqsk93Rq41q85Ex0WGvjOUtmwP9VMC/9wSIcSq7kpaT9tSDSF02rcVc1MTU9BJ7Lz5OqJv5k1enSRwmn/7iiBftTpADiJsHMOCDsoi/Vt5mxKkk+XJ5ghGef/dRpGrmpdw4Sc0w1XbdyfKi/P2WoWz1O6w0DfltVN6KkTFfKX43WBv4FvL5XNiWkSFepvenTiqrj3Z3rCvG3y35+2mnV/Phl6vmtLCf3TpEXMX63ZL5VC/OXbu7tItRJafRmAPRB2zgFhB6Vlz+Hj8snSeJmxcq9ZUM+pc/1KZiE8ncJdlBlF6/elyMtztpnA5Aw9V7aqIfd0q29WPlbJaZky4K2lsi053cxWmjq0wzkNfVlF/wQNn7raFB9rqHFuKfHuwl0yduZG8fH2ko9v6yDn161kdVMBuBnCzjkg7KCk6Xo0Gk604NhZi6MBRGtOtBfHGVDO1bq9Gnq2mhofpUHgqlbVzWM+OON3sx6O7hP1ydAOZtuH8jQ9/tpJi83QW5Oq4TKqZyO57YMV5nf3xGVN5NYudaxuIgA3RNg5B4QdlJSUEzkyacEOeW/RLsnMObkFgy7eN7BDrFwcF12szTZPZ03CMRN6ft5ysNDt2iMydej5Elup/G08qVtK9J2wUA6l/9kDpis0v3RdCwqSAZwWYeccEHZQEisUv//bbnnj5x0m8DgLjh/uHeeqQSkNq+KPmh4kXRlZN+HUHp0aFctf0DndlhLaw/P5HZ0kyJ+CZACnR9g5B4QdFFduXr58sWqf/G/OVtfMqgbRofJgrzjp3ji6zHokdCsHXWQvJKD8L501e2OSfPf7fhnVK870VAHAmbBdBFCK9N8IOkPqhR+3yPbkdHNbtYhAue+ShmZ2ldbSlKXyVJ9zNrrBqJ4AoKQQdoBztHTnYbOar65MrCoE+8ldF9aXmzrWYg0YAHBDhB2giDYnpsrzszbL/D+KggP9vGVIlzry7wvqSXgxdgAHAJQNwg5wFgdSTshLP22VGav2msUAdYiqf7uacm+3BhLNZpQA4PYIO8AZpGWenEb+zsI/p5Ff2qyKPNCjka1qZADA7gg7wCly8vJl6rJ4szeVc9XjtrUqyqN9GkvrWOt3DQcAnBvCDlBghtWPGxLl+R+2yK5Dx81tdaNC5KHecdKjSQwL2wFAOUXYAURk5Z6jMu77TbJiz1FzXfdoGtG9gfRvHyt+JbTqMQDAGoQdeLTdh46baeSz1ie6ZlgN/VddGda1roQxwwoAbIGwA490LCPbbLPw0ZI9kpvvEB2h0k0677+kkVSJYIYVANgJYQceR3fY7v/mEtmcmGauX9iostnDKq4KW4UAgB0RduBRtAj5oc/XmaATFRogr/RvKZ3rR1ndLABAKSLswKPomjnfrt0vvt5eMnFg61LdkRwA4B6YZgKPsWTnYRk3a7O5/FifxgQdAPAQhB14zJYPwz9ZJXn5DrmyVXUZ1Km21U0CAJQRwg5sLys3T+74aJUcSs+WxlXD5dkrm7FAIAB4EMIObG/MtxtlTcIxCQ/0lckD20iQv4/VTQIAlCHCDmxt2vIE+WRpvFlH55UbWklspWCrmwQAKGOEHdjW73uPyWNfrzeX7+veUC5qFG11kwAAFiDswJaOHM82dTrZufnSvXG0DL+ovtVNAgBYhLAD28nNy5e7p66SfcdOSJ2oEHnp+pbi7U1BMgB4KsIObOe/P22VRdsPS5Cfj0wa2EbC2dATADwaYQe2MmvdAZm0YIe5PP6a5tKoSpjVTQIAWIywA9vYnpwmD0xfay4P/VcdubxFNaubBAAor2EnISFB9u7d67q+bNkyGTFihLz55psl2TagyNIyc2TYhyvleHaenF83Uh7qFWd1kwAA5Tns3HjjjTJ//nxzOTExUS655BITeP7zn//I2LFjS7qNwFl3MtcenZ0Hj0uV8ECZcGNr8fWh0xIAcFKxvhHWr18v7du3N5enTZsm5513nvz222/y8ccfy5QpU4rzkECxt4J48psN8uOGJPH38TY7mUeFBljdLACAG/Etzg/l5ORIQMDJL5Q5c+bIFVdcYS7HxcXJgQMHSraFwN/U6NwzdY1sPJBqro/p21RaxVa0ulkAADv07DRt2lQmTZokv/76q8yePVt69eplbt+/f79UqlSppNsI/GXY6qMle+Sy1xaaoBMZ4i9v3dxWbmgfa3XTAAB26dl5/vnn5corr5QXXnhBBg0aJC1atDC3f/PNN67hLaC0VkZ+cMbvMmdTkrn+rwZR8uK1LSQ6PNDqpgEA3JSXQ/+ZXAx5eXmSmpoqFSv+OWywe/duCQ4Olujo8rUHkb6OiIgISUlJkfDwcKubgzP4ddtBuX/aWjmYlmXqcx7s1Uhu7VyH1ZEBwEOlFvH7u1g9O0oz0sqVK2XHjh1mdlZYWJj4+/ubsAOUdBHyCz9skbcX7jLX60eHyiv9W0rTahFWNw0AUA4UK+zs2bPH1OnEx8dLVlaWmXquYUeHt/S61vMAJWFbUprc8+ka2fRHEfJN59eSRy9tLEH+PlY3DQBg5wLle++9V9q2bStHjx6VoKAg1+1axzN37tySbB88lPYcfvhHEfKmP4qQ3765rTzV7zyCDgCg9Ht2dBaWrqujw1YF1a5dW/bt21echwRcDqdnyUOfaxFysrlOETIAoMzDTn5+vilQPpVuIaHDWUBxbdyfKoPeW+YqQn6od5zc0qk2RcgAgLIdxurRo4e8/PLLruteXl6Snp4uo0ePlksvvbT4rYHHGztzgwk6DaJD5au7OsuQLsy2AgBY0LPz4osvSs+ePaVJkyaSmZlpZmNt27ZNoqKiZOrUqf+wSfBUaxKOyZKdR8TX20vev7W9VKvwZz0YAABlGnZq1Kgha9eulc8++8yca6/OkCFDZMCAAYUKloFzMennHea8b8vqBB0AQIkp9jo7vr6+JtzoCfindhxMlx83JprLt19Q1+rmAABspFg1O++//7589913rusPPvigVKhQQTp16mTW4AHO1du/7hRdy7t742hpEEOROwDA4rDz7LPPuoarFi9eLBMmTJDx48ebmp377ruvBJsHT5Ccmimfrzy5ZMHtF9SzujkAAJsp1jBWQkKC1K9f31z+6quv5JprrpFhw4ZJ586d5cILLyzpNsLm3l20W7Lz8qVtrYrStnak1c0BANhMsXp2QkND5fDhw+byTz/9ZLaLUIGBgXLixImSbSFsLTUzRz5ecnLo89/06gAA3KVnR8PNbbfdJq1atZKtW7e61tbZsGGDWUUZKKpPlsZLWlauWVenW1y01c0BANhQsXp2Xn/9denYsaMcPHhQPv/8c6lUqZK5XXdBv+GGG0q6jbDxbubv/rGT+bCudVk8EABQKrwcuuOih0tNTZWIiAhJSUmR8PBwq5vjMT5bHi8Pfb5OqkYEyoJRF4m/b7GyNwDAQ6UW8fu7WN8uP/zwgyxcuLBQT0/Lli3NSsq6EzpwNvn5Dpn8y05zWbeEIOgAAEpLsb5hRo0aZdKUWrdunYwcOdLU7ezatUvuv//+km4jbOinjUmy8+BxCQ/0lf7tY61uDgDAxopVoKyhRvfFUlqzc9lll5m1d1atWsVGoDgrHTmdtODk1hA3dawloQHFXsgbAIDS6dnx9/eXjIwMc3nOnDlmF3QVGRnp6vE5V88995zZPX3EiBGu23ST0bvuussUQOt096uvvlqSkpIK/Vx8fLz06dNHgoODJTo62vQ65ebmFqsNKBtLdx0xm37q0NXgTnWsbg4AwOaK9U/qLl26mOEqXURw2bJlZkNQpdPQdZPQc7V8+XKZPHmyNG/evNDtuhqzbksxffp0U4A0fPhwueqqq2TRokXm/ry8PBN0qlSpIr/99pscOHBAbr75ZvHz8zM9TXBPk//o1bm2TQ2pHBZgdXMAADZXrJ4d3R5CNwKdMWOGTJw4UapXr25unzVrlvTq1eucHkt3TNfNRN966y2pWLGi63atrH7nnXfkpZdekosvvljatGkj7733ngk1S5YscS1ouHHjRvnoo49MgXTv3r3lqaeeMgXT2dnZxXlpKGWbE1Nl/paDorPMdbo5AABuGXZiY2Nl5syZsnbtWhkyZIjr9v/973/y6quvntNj6TCV9s5079690O26Zk9OTk6h2+Pi4sxz635cSs+bNWsmMTExrmN69uxphtJ0gUO4n8kLTs7A6t2sqtSqFGJ1cwAAHqDYlaE6hKT7Ym3atMlcb9q0qVxxxRXi4+NT5Mf49NNPTVGzDmOdKjEx0dQG6W7qBWmw0fucxxQMOs77nfedSVZWljk5FbfOCOdm79EM+WbtfnP59q5sDQEAcOOws337djPrat++fdKoUSNz27hx46RmzZqmxqZevXpF2kz03nvvldmzZ5s9tcqStnXMmDFl+pwQefvXXZKX75DO9StJsxoRVjcHAOAhijWMdc8995hAo4FFe2b0pLOi6tSpY+4rCh2mSk5OltatW5v6Hz0tWLDADIPpZe2h0bqbY8eOFfo5nY2lBclKz0+dneW87jzmdB555BFTE+Q86etA6Tp6PFs+W37y93w7G34CANy9Z0dDiRYJ61RzJ50ertPHdYZWUXTr1s0sSFjQLbfcYupyHnroIdNLpLOq5s6da6acqy1btphQpftyKT1/5plnTGjSaedKe4p0yWjnOkCnExAQYE4oOx8s3iMncvKkabVw6VI/yurmAAA8SLHCjgaFtLS0086s0jqboggLC5Pzzjuv0G0hISEmNDlv1+JnneKuoUoDzN13320Czvnnn2/u1/V9NNTcdNNNMn78eFOn89hjj5miZ8KM+ziRnSfvL97t6tXR9ZQAAHDrYSxdMXnYsGGydOlSsxqunrSn5/bbbzdFyiVFZ3fpc2nPTteuXc3Q1BdffOG6X4uhdVaYnmsIGjhwoFlnZ+zYsSXWBvxz01YkyJHj2VIzMkh6n3fm4UUAANxm13Otoxk0aJB8++23ZqhJ6TTxvn37mrVwTp1B5e7Y9bz05Obly4X//Vn2Hj0hT/VtKjd1rG11kwAANlHU7+9iDWNpmPn666/NrCzn1PPGjRtL/fr1i99i2NJ36w6YoFMpxF+ubVvT6uYAADxQkcPO2XYznz9/vuuyrnoMnNzw8+QigoM71ZZAv6KvwQQAQJmHndWrVxfpOIpP4TRrfaJsOpAqwf4+ZndzAADcOuwU7LkBirIH1qjpa83lQZ1qS4Xgos3SAwDALWZjAX/nUHqWDJmyQo5n58n5dSPlvu4NrW4SAMCDEXZQojJz8uTfH66UfcdOSO1KwTJpYBvx9+VjBgCwDt9CKNGC5Ee+WCcr9xyV8EBfeWdwO4avAACWI+ygxLzx8w75cvU+8fH2kjcGtJF6lUOtbhIAAIQdlIxZ6w7ICz9uMZfHXNFUujRg/ysAgHsg7OAfW7c3Re6btsa1ns7A85lmDgBwH4Qd/CNJqZly2wfLJTMnXy5oWFke69PY6iYBAFAIYQf/aDfz295fIUmpWdIgOlReu7GV+PrwkQIAuBe+mVAs+fkOGTl9jazblyKRIf7yzqB2Eh54clNYAADcCWEHxfK/OVvl+3WJ4ufjZdbSia0UbHWTAAA4LcIOztlXq/fJa/O2m8vjrmou7etEWt0kAADOiLCDc6ILBj74+e/m8u0X1JNr2tSwukkAAPwtwg6KbO/RDPn3hyskOzdfejSJkQd7NrK6SQAAnBVhB0Wy6UCqmXl1KD1bmlQNl/9d31K8vb2sbhYAAGfle/ZD4Ml7XS3aflgm/7JDft12yNxWOSxA3hncVkIC+OgAAMoHvrHwFzl5+fL9ugMyecFO2Xgg1dymnTi9m1WVkZc0lKoRQVY3EQCAIiPswCU9K1c+XRYv7y3aLfuOnTC3Bfn5yPXtasqtneswvRwAUC4RdmC2fNCA8/HSPZKWmWtuiwr1l0EdT+5zVTHE3+omAgBQbIQdD7YtKU3e/GWnfLVmn+TkOcxtdaNCZGjXunJlq+oS6OdjdRMBAPjHCDseKC/fIQ9MXytfrt7nuq1trYoyrGtd6d44hllWAABbIex4oMU7Dpug4+Ul0rNJFdOT06ZWRaubBQBAqSDseKA1CUfNeZ9mVWXCja2tbg4AAKWKRQU90JqEFHPesmYFq5sCAECpI+x44EKBaxKOmcutYgk7AAD7I+x4GF0/51B6lvh6e0nTahFWNwcAgFJH2PEwa/8YwoqrGsbUcgCARyDseGhxMvU6AABPQdjx0J6dFjUIOwAAz0DY8SC5efmybt/JsENxMgDAUxB2PMiWpDQ5kZMnYQG+Ujcq1OrmAABQJgg7HjiE1bxmBFtCAAA8BmHHg1CcDADwRIQdD+JcTJDiZACAJyHseIj0rFzZlpxuLtOzAwDwJIQdD/H73mPicIhUiwiU6PBAq5sDAECZIex4WHFyS6acAwA8DGHHQ1CcDADwVIQdD0FxMgDAUxF2PEBiSqYkpWaJLq3TrAY7nQMAPAthx4OGsBrGhEmwv6/VzQEAoEwRdjzAmj+Kk9kPCwDgiQg7HtSzQ70OAMATEXZsLi/fIev2Mu0cAOC5CDs2tz05XY5n50mwv480iA6zujkAAJQ5wo6HDGE1qx4hPux0DgDwQIQdDylOZggLAOCpCDsesphgS4qTAQAeirBjYxnZubIlMdVcpmcHAOCpCDs2tn5fquQ7RGLCA6RqRJDVzQEAwBKEHRtjfR0AAAg7traW4mQAAAg7dkZxMgAAhB3bSk7LlH3HTogXO50DADwcYcfmQ1gNokMlLNDP6uYAAGAZwo5NUZwMAMBJhB2bojgZAICTCDs2lJ/vkLV/FCfTswMA8HSEHRvaeShd0rJyJdDPW+KqsNM5AMCzEXZsvPmn7nTu68NbDADwbHwT2hDFyQAA/ImwY0MUJwMA8CfCjs1k5uTJpgMndzqnZwcAAMKO7WzYnyK5+Q6JCvWXGhXZ6RwAAMKOTYuTW9asIF66VwQAAB7O0rAzbtw4adeunYSFhUl0dLT069dPtmzZUuiYzMxMueuuu6RSpUoSGhoqV199tSQlJRU6Jj4+Xvr06SPBwcHmcUaNGiW5ubniyZt/MoQFAIAbhJ0FCxaYILNkyRKZPXu25OTkSI8ePeT48eOuY+677z759ttvZfr06eb4/fv3y1VXXeW6Py8vzwSd7Oxs+e233+T999+XKVOmyBNPPCGeyLmYIMXJAACc5OVwOBziJg4ePGh6ZjTUdO3aVVJSUqRy5cryySefyDXXXGOO2bx5szRu3FgWL14s559/vsyaNUsuu+wyE4JiYmLMMZMmTZKHHnrIPJ6/v/9Znzc1NVUiIiLM84WHh0t5dTg9S9o8PcdcXju6h0QEsQEoAMC+ivr97VY1O9pYFRkZac5Xrlxpenu6d+/uOiYuLk5iY2NN2FF63qxZM1fQUT179jS/gA0bNpz2ebKyssz9BU92sHbvyV6dupVDCDoAALhb2MnPz5cRI0ZI586d5bzzzjO3JSYmmp6ZChUKD8losNH7nMcUDDrO+533nalWSJOg81SzZk2xVXEy9ToAALhf2NHanfXr18unn35a6s/1yCOPmF4k5ykhIUHsVJxMvQ4AAH/yFTcwfPhwmTlzpvzyyy9So0YN1+1VqlQxhcfHjh0r1Lujs7H0Pucxy5YtK/R4ztlazmNOFRAQYE52oqVXruLkmoQdAADcomdHv6A16Hz55Zcyb948qVOnTqH727RpI35+fjJ37lzXbTo1Xaead+zY0VzX83Xr1klycrLrGJ3ZpYVKTZo0EU+x+3CGpJzIEX9f3em8/BZZAwBgq54dHbrSmVZff/21WWvHWWOjdTRBQUHmfMiQIXL//febomUNMHfffbcJODoTS+lUdQ01N910k4wfP948xmOPPWYe2269N0XZ/LNptXATeAAAgBuEnYkTJ5rzCy+8sNDt7733ngwePNhc/t///ife3t5mMUGdRaUzrd544w3XsT4+PmYI7I477jAhKCQkRAYNGiRjx46V8rrdQ8KRE3JxXPQ5hRbn5p8sJggAgBuvs2MVd1lnJy/fIe2fmSOHj2dL1YhAGda1rvRvFytB/j5n/dm+ry8yNTuv9G8pfVtWL5P2AgBgpXK5zo6n23P4uAk66kBKpoz5dqN0fn6eTJi3zdTjnElWbp5s2n9yrSCKkwEAKIyw40Y2HUhz1d08c+V5EhsZLEeOZ8t/f9oqnZ+bJ8/N2iwH07JO+3PZeflSMdjP/AwAAPgTYceNbDpwsnemeY0IGdChlswbeYEZlmoUEybpWbkyacEO6fL8PHn8q/WScCTD9XNr4k8WJ7dgp3MAANxznR0UDjuNq54cd/T18Tb1N5c3ryZzNyfL6/O3m4UDP1yyRz5ZFi99W1aTOy6oJ2v3UpwMAMCZEHbcOOw4eXt7ySVNYqR742hZvPOwTPx5h/y67ZB8sWqfOTlnbbFyMgAAf0XYcRPHMrJlf0qmudyoSthpj9Ehqk71osxJZ1698fN2+XFDkmTn5pv72RMLAIC/Iuy4WXFyjYpBEh549h3LtT5n8k1tZVtSmny0ZI/UrRwqFUP8y6ClAACUL4QdN7E58fRDWGfTICZMxvQ9uUs8AAD4K2ZjuXm9DgAA+GcIO242jNWk6unrdQAAQPEQdtxAbl6+bEk6GXbo2QEAoGQRdtzArkPHzYyqEH8fqVmRFZABAChJhB03sPGPep24quFmTR0AAFByCDtuVK8Td4b1dQAAQPERdtwAM7EAACg9hB03QNgBAKD0EHYsdjg9S5LTskQ3K2cYCwCAkkfYsdjmxJP1OrUigyUkgAWtAQAoaYQdizGEBQBA6SLsuMm0c8IOAAClg7DjJtPOCTsAAJQOwo6FdNXk7cmssQMAQGki7Fhox8F0yclzSFigr9SoGGR1cwAAsCXCjjsUJ1cJFy+dew4AAEocYcctZmIxhAUAQGkh7FiI4mQAAEofYcdCmxOZdg4AQGkj7FgkOS1TDqVni7eXSCNmYgEAUGoIOxYPYdWJCpFAPx+rmwMAgG0RdiwuTo5jCAsAgFJF2LE47DQh7AAAUKoIOxZh2jkAAGWDsGOBzJw82XHwuLnMTCwAAEoXYccC25PTJS/fIRWC/aRKeKDVzQEAwNYIOxbYyDYRAACUGcKOpfU6DGEBAFDaCDsW2OzaJoLiZAAAShthp4w5HA7ZxDYRAACUGcJOGUtMzZRjGTni4+0l9aNDrW4OAAC2R9ixqF6nXmW2iQAAoCwQdizaE4shLAAAygZhx6pp54QdAADKBGGnjDHtHACAskXYKUMnsvNk9yHnNhFMOwcAoCwQdsrQlqQ0yXeIRIX6S3QY20QAAFAWCDtlaPMfQ1hxVRjCAgCgrBB2LKnXYQgLAICyQtgpQ0w7BwCg7BF2ygjbRAAAYA3CThnZe/SEpGXmip+Pl9SrzDYRAACUFcJOGdfr1I8OE39ffu0AAJQVvnXLvF6H4mQAAMoSYaeMe3aaUK8DAECZIuyUEWdxMmvsAABQtgg7ZSA9K1f2HM4wlxnGAgCgbBF2ysCWxJP1OtFhAVIpNMDq5gAA4FEIO2WAnc4BALAOYacMEHYAALAOYacMsCcWAADWIeyUsvx8h2z+o2aHaecAAJQ9wk4piz+SIRnZeWbV5DpRIVY3BwAAj0PYKaMhrEYxYeLrw68bAICyxrdvGYWduCrU6wAAYAXCTinb6NoTi3odAACsQNgpZZv/2CaCsAMAgDUIO6UoNTNH9h49YS4zEwsAAGsQdkrR5j+GsKpFBEpEsJ/VzQEAwCPZJuy8/vrrUrt2bQkMDJQOHTrIsmXLrG4SKycDAOAGbBF2PvvsM7n//vtl9OjRsmrVKmnRooX07NlTkpOTLW0XYQcAAOvZIuy89NJLMnToULnlllukSZMmMmnSJAkODpZ3333X0nYRdgAAsF65DzvZ2dmycuVK6d69u+s2b29vc33x4sWn/ZmsrCxJTU0tdCppDodDsvMc4uUlEseeWAAAWMZXyrlDhw5JXl6exMTEFLpdr2/evPm0PzNu3DgZM2ZMqbbLy8tLZt37LzmelStBfj6l+lwAAMDGPTvF8cgjj0hKSorrlJCQUGrPFRLgK97eXqX2+AAAwOY9O1FRUeLj4yNJSUmFbtfrVapUOe3PBAQEmBMAALC/ct+z4+/vL23atJG5c+e6bsvPzzfXO3bsaGnbAACA9cp9z47SaeeDBg2Stm3bSvv27eXll1+W48ePm9lZAADAs9ki7Fx//fVy8OBBeeKJJyQxMVFatmwpP/zww1+KlgEAgOfxcugcaQ+nU88jIiJMsXJ4OGviAABgp+/vcl+zAwAA8HcIOwAAwNYIOwAAwNYIOwAAwNYIOwAAwNYIOwAAwNYIOwAAwNYIOwAAwNZssYLyP+VcV1EXJwIAAOWD83v7bOsjE3ZEJC0tzZzXrFnT6qYAAIBifI/rSspnwnYRf+ySvn//fgkLCxMvL68STZwaoBISEjx2GwpP/x3w+j379StP/x14+utXnv47SC3F168RRoNOtWrVxNv7zJU59Oxo4ZK3t9SoUaPUHl/fXE/8gBfk6b8DXr9nv37l6b8DT3/9ytN/B+Gl9Pr/rkfHiQJlAABga4QdAABga4SdUhQQECCjR482557K038HvH7Pfv3K038Hnv76laf/DgLc4PVToAwAAGyNnh0AAGBrhB0AAGBrhB0AAGBrhB0AAGBrhJ1S9Prrr0vt2rUlMDBQOnToIMuWLRNP8OSTT5qVqAue4uLixM5++eUXufzyy80qnvp6v/rqq0L36zyAJ554QqpWrSpBQUHSvXt32bZtm3jK6x88ePBfPhO9evUSuxg3bpy0a9fOrMIeHR0t/fr1ky1bthQ6JjMzU+666y6pVKmShIaGytVXXy1JSUniSb+DCy+88C+fg9tvv13sYOLEidK8eXPXwnkdO3aUWbNmecz7P/Esr9/q956wU0o+++wzuf/++810u1WrVkmLFi2kZ8+ekpycLJ6gadOmcuDAAddp4cKFYmfHjx8377EG3NMZP368vPrqqzJp0iRZunSphISEmM+D/gH0hNevNNwU/ExMnTpV7GLBggXmi2zJkiUye/ZsycnJkR49epjfi9N9990n3377rUyfPt0cr1vUXHXVVeJJvwM1dOjQQp8D/X/DDnQV/ueee05WrlwpK1askIsvvlj69u0rGzZs8Ij3v8ZZXr/l771OPUfJa9++veOuu+5yXc/Ly3NUq1bNMW7cOIfdjR492tGiRQuHp9L/rb788kvX9fz8fEeVKlUcL7zwguu2Y8eOOQICAhxTp0512P31q0GDBjn69u3r8BTJycnm97BgwQLX++3n5+eYPn2665hNmzaZYxYvXuzwhN+BuuCCCxz33nuvpe0qSxUrVnS8/fbbHvn+F3z97vDe07NTCrKzs0261aGKgvtv6fXFixeLJ9AhGh3SqFu3rgwYMEDi4+PFU+3atUsSExMLfR50Lxcd2vSUz4P6+eefzfBGo0aN5I477pDDhw+LXaWkpJjzyMhIc65/D7Sno+BnQId2Y2NjbfsZOPV34PTxxx9LVFSUnHfeefLII49IRkaG2E1eXp58+umnpldLh3M87f3PO+X1u8N7z0agpeDQoUPmzY6JiSl0u17fvHmz2J1+iU+ZMsV8qWlX5ZgxY+Rf//qXrF+/3oznexoNOup0nwfnfXanQ1jaZV+nTh3ZsWOHPProo9K7d2/zh97Hx0fsJD8/X0aMGCGdO3c2f9SVvs/+/v5SoUIFj/gMnO53oG688UapVauW+YfQ77//Lg899JCp6/niiy/EDtatW2e+3HV4WutyvvzyS2nSpImsWbPGI97/dWd4/e7w3hN2UOL0S8xJC9Y0/OiHfNq0aTJkyBBL2wZr9O/f33W5WbNm5nNRr14909vTrVs3sROtW9Fgb/c6teL8DoYNG1boc6AF+/r+awDWz0N5p//A02CjvVozZsyQQYMGmfocT9HoDK9fA4/V7z3DWKVAu+n0X6unVtrr9SpVqoin0X/NNGzYULZv3y6eyPme83n4kw5v6v8ndvtMDB8+XGbOnCnz5883BZtO+j7r8PaxY8ds/xk40+/gdPQfQsounwPtvalfv760adPGzE7Tov1XXnnFY95//zO8fnd47wk7pfSG65s9d+7cQt26er3g+KWnSE9PN+ldk7wn0qEb/YNW8POQmppqZmV54udB7d2719Ts2OUzoXXZ+iWv3fbz5s0z73lB+vfAz8+v0GdAu/C1ls0un4Gz/Q5OR3sBlF0+B6fSv/tZWVke8f7/3et3i/festJom/v000/NbJspU6Y4Nm7c6Bg2bJijQoUKjsTERIfdjRw50vHzzz87du3a5Vi0aJGje/fujqioKDM7w67S0tIcq1evNif93+qll14yl/fs2WPuf+6558z7//XXXzt+//13MzOpTp06jhMnTjjs/vr1vgceeMDMOtHPxJw5cxytW7d2NGjQwJGZmemwgzvuuMMRERFhPvcHDhxwnTIyMlzH3H777Y7Y2FjHvHnzHCtWrHB07NjRnOzibL+D7du3O8aOHWteu34O9P+FunXrOrp27eqwg4cfftjMPNPXpv+P63UvLy/HTz/95BHv/8N/8/rd4b0n7JSi1157zXy4/f39zVT0JUuWODzB9ddf76hatap53dWrVzfX9cNuZ/Pnzzdf8qeedMq1c/r5448/7oiJiTEhuFu3bo4tW7Y4POH165ddjx49HJUrVzbTb2vVquUYOnSorYL/6V67nt577z3XMRps77zzTjMdNzg42HHllVeaMOApv4P4+Hjz5RYZGWn+H6hfv75j1KhRjpSUFIcd3HrrreazrX/39LOu/487g44nvP+3/s3rd4f33kv/UzZ9SAAAAGWPmh0AAGBrhB0AAGBrhB0AAGBrhB0AAGBrhB0AAGBrhB0AAGBrhB0AAGBrhB0AOIVuUOrl5fWXvYwAlE+EHQAAYGuEHQAAYGuEHQBuuVvyuHHjzM7ZQUFB0qJFC5kxY0ahIabvvvtOmjdvLoGBgXL++efL+vXrCz3G559/Lk2bNpWAgACpXbu2vPjii4Xu192YH3roIalZs6Y5pn79+vLOO+8UOmblypXStm1bCQ4Olk6dOpmdqgGUP4QdAG5Hg84HH3wgkyZNkg0bNsh9990nAwcOlAULFriOGTVqlAkwy5cvl8qVK8vll18uOTk5rpBy3XXXSf/+/WXdunXy5JNPyuOPPy5Tpkxx/fzNN98sU6dOlVdffVU2bdokkydPltDQ0ELt+M9//mOeY8WKFeLr6yu33nprGf4WAJQUNgIF4Fa0xyUyMlLmzJkjHTt2dN1+2223SUZGhgwbNkwuuugi+fTTT+X666839x05ckRq1KhhwoyGnAEDBsjBgwflp59+cv38gw8+aHqDNDxt3bpVGjVqJLNnz5bu3bv/pQ3ae6TPoW3o1q2bue3777+XPn36yIkTJ0xvEoDyg54dAG5l+/btJtRccsklpqfFedKenh07driOKxiENBxpeNEeGqXnnTt3LvS4en3btm2Sl5cna9asER8fH7ngggv+ti06TOZUtWpVc56cnFxirxVA2fAto+cBgCJJT08359oLU7169UL3aW1NwcBTXFoHVBR+fn6uy1on5KwnAlC+0LMDwK00adLEhJr4+HhTNFzwpMXETkuWLHFdPnr0qBmaaty4sbmu54sWLSr0uHq9YcOGpkenWbNmJrQUrAECYF/07ABwK2FhYfLAAw+YomQNJF26dJGUlBQTVsLDw6VWrVrmuLFjx0qlSpUkJibGFBJHRUVJv379zH0jR46Udu3ayVNPPWXqehYvXiwTJkyQN954w9yvs7MGDRpkCo61QFlne+3Zs8cMUWnNDwB7IewAcDsaUnSGlc7K2rlzp1SoUEFat24tjz76qGsY6bnnnpN7773X1OG0bNlSvv32W/H39zf36bHTpk2TJ554wjyW1ttoOBo8eLDrOSZOnGge784775TDhw9LbGysuQ7AfpiNBaBccc6U0qErDUEAcDbU7AAAAFsj7AAAAFtjGAsAANgaPTsAAMDWCDsAAMDWCDsAAMDWCDsAAMDWCDsAAMDWCDsAAMDWCDsAAMDWCDsAAMDWCDsAAEDs7P98EechXaFLIAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(k=4, n=X_train.shape[1] , method=\"batch\", alpha=0.01, max_iter=10000, lambda_=0.6, use_penalty=True)\n",
    "model.fit(X_train, Y_train_encoded)\n",
    "preds = model.predict(X_1test)\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.99      0.11       136\n",
      "           1       0.14      0.01      0.02      1137\n",
      "           2       0.44      0.01      0.03      1026\n",
      "           3       0.00      0.00      0.00       110\n",
      "\n",
      "    accuracy                           0.07      2409\n",
      "   macro avg       0.16      0.25      0.04      2409\n",
      "weighted avg       0.25      0.07      0.03      2409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report: \", classification_report(y_1test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/06 05:14:32 INFO mlflow.tracking.fluent: Experiment with name 'st124909-a3-Ridge' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/439733742680906594', creation_time=1743916882623, experiment_id='439733742680906594', last_update_time=1743916882623, lifecycle_stage='active', name='st124909-a3-Ridge', tags={}>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Setting MLflow authentication credentials as environment variables\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'admin'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'password'\n",
    "\n",
    "# Pointing MLflow to the remote tracking server\n",
    "mlflow.set_tracking_uri(\"https://mlflow.ml.brain.cs.ait.ac.th/\")\n",
    "\n",
    "# Set (and create if not exist) an experiment for tracking\n",
    "mlflow.set_experiment(\"st124909-a3-Ridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ML\\MLenv\\lib\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:166: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import cloudpickle\n",
    "\n",
    "class CustomLogisticWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, trained_model):\n",
    "        self.trained_model = trained_model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        return self.trained_model.predict(model_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 3.6680750114400897\n",
      "Loss at iteration 500 71.49940117529337\n",
      "Loss at iteration 1000 87.16688789266126\n",
      "Loss at iteration 1500 73.22151334499046\n",
      "Loss at iteration 2000 60.78046299027453\n",
      "Loss at iteration 2500 55.96540131104049\n",
      "Loss at iteration 3000 80.65636476221158\n",
      "Loss at iteration 3500 70.70581678659524\n",
      "Loss at iteration 4000 79.10468182180406\n",
      "Loss at iteration 4500 68.65947865642255\n",
      "Loss at iteration 5000 81.22370315678033\n",
      "Loss at iteration 5500 83.61398492532174\n",
      "Loss at iteration 6000 87.08927861583534\n",
      "Loss at iteration 6500 88.43697572236566\n",
      "Loss at iteration 7000 64.21772116914306\n",
      "Loss at iteration 7500 66.140936655001\n",
      "Loss at iteration 8000 59.700950324580944\n",
      "Loss at iteration 8500 71.74231495647976\n",
      "Loss at iteration 9000 70.94734304651084\n",
      "Loss at iteration 9500 82.6638847028258\n",
      "time taken: 1.2698018550872803\n",
      "🏃 View run ridge_logistic_run at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594/runs/5060144bf3dc48728d6ff80b02784bef\n",
      "🧪 View experiment at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Train model\n",
    "model = LogisticRegression(k=4, n=X_train.shape[1], method=\"minibatch\", alpha=0.01, max_iter=10000, lambda_=0.6, use_penalty=True)\n",
    "model.fit(X_train, Y_train_encoded)\n",
    "preds = model.predict(X_1test)\n",
    "\n",
    "# คำนวณ metric\n",
    "accuracy = accuracy_score(y_1test, preds)\n",
    "f1 = f1_score(y_1test, preds, average=\"macro\")\n",
    "\n",
    "# Log everything to MLflow\n",
    "with mlflow.start_run(run_name=\"ridge_logistic_run\", nested=True):\n",
    "    mlflow.log_param(\"model_type\", \"Custom LogisticRegression\")\n",
    "    mlflow.log_param(\"lambda_\", model.lambda_)\n",
    "    mlflow.log_param(\"method\", model.method)\n",
    "    mlflow.log_param(\"alpha\", model.alpha)\n",
    "    mlflow.log_param(\"max_iter\", model.max_iter)\n",
    "\n",
    "    # Log overall metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"macro_precision\", macro_precision)\n",
    "    mlflow.log_metric(\"macro_recall\", macro_recall)\n",
    "    mlflow.log_metric(\"macro_f1\", macro_F1)\n",
    "\n",
    "    # Log per-class metrics (optional)\n",
    "    for i in range(num_classes):\n",
    "        mlflow.log_metric(f\"precision_class_{i}\", precision_per_class[i])\n",
    "        mlflow.log_metric(f\"recall_class_{i}\", recall_per_class[i])\n",
    "        mlflow.log_metric(f\"f1_class_{i}\", f1_per_class[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/189153763932796199', creation_time=1743911296422, experiment_id='189153763932796199', last_update_time=1743913485834, lifecycle_stage='active', name='st124909-a3-Ridge', tags={}>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Setting MLflow authentication credentials as environment variables\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'admin'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'password'\n",
    "\n",
    "# Pointing MLflow to the remote tracking server\n",
    "mlflow.set_tracking_uri(\"https://mlflow.ml.brain.cs.ait.ac.th/\")\n",
    "\n",
    "# Set (and create if not exist) an experiment for tracking\n",
    "mlflow.set_experiment(\"st124909-a3-Ridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 3.327789828143062\n",
      "Loss at iteration 500 56.569657333603786\n",
      "Loss at iteration 1000 63.99647576511465\n",
      "Loss at iteration 1500 84.96045136138257\n",
      "Loss at iteration 2000 76.14288058359247\n",
      "Loss at iteration 2500 70.2231204520798\n",
      "Loss at iteration 3000 74.03277603056486\n",
      "Loss at iteration 3500 54.36441686033828\n",
      "Loss at iteration 4000 85.65011100741613\n",
      "Loss at iteration 4500 59.50750889270753\n",
      "Loss at iteration 5000 87.83316786463705\n",
      "Loss at iteration 5500 56.16163474808319\n",
      "Loss at iteration 6000 72.32921952335569\n",
      "Loss at iteration 6500 69.15336984234123\n",
      "Loss at iteration 7000 79.00867235664943\n",
      "Loss at iteration 7500 79.70830059540373\n",
      "Loss at iteration 8000 99.44081220359368\n",
      "Loss at iteration 8500 58.03282745139679\n",
      "Loss at iteration 9000 62.478330919607856\n",
      "Loss at iteration 9500 84.7440597300405\n",
      "time taken: 1.2880656719207764\n",
      "🏃 View run ridge_logistic_run at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594/runs/e9ac7d417b9a4883bf8c943241677322\n",
      "🧪 View experiment at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Train model\n",
    "model = LogisticRegression(k=4, n=X_train.shape[1], method=\"minibatch\", alpha=0.01, max_iter=10000, lambda_=0.6, use_penalty=True)\n",
    "model.fit(X_train, Y_train_encoded)\n",
    "preds = model.predict(X_1test)\n",
    "\n",
    "# คำนวณ metric\n",
    "accuracy = accuracy_score(y_1test, preds)\n",
    "f1 = f1_score(y_1test, preds, average=\"macro\")\n",
    "\n",
    "# Log everything to MLflow\n",
    "with mlflow.start_run(run_name=\"ridge_logistic_run\", nested=True):\n",
    "    mlflow.log_param(\"model_type\", \"Custom LogisticRegression\")\n",
    "    mlflow.log_param(\"lambda_\", model.lambda_)\n",
    "    mlflow.log_param(\"method\", model.method)\n",
    "    mlflow.log_param(\"alpha\", model.alpha)\n",
    "    mlflow.log_param(\"max_iter\", model.max_iter)\n",
    "\n",
    "    # Log overall metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"macro_precision\", macro_precision)\n",
    "    mlflow.log_metric(\"macro_recall\", macro_recall)\n",
    "    mlflow.log_metric(\"macro_f1\", macro_F1)\n",
    "\n",
    "    # Log per-class metrics (optional)\n",
    "    for i in range(num_classes):\n",
    "        mlflow.log_metric(f\"precision_class_{i}\", precision_per_class[i])\n",
    "        mlflow.log_metric(f\"recall_class_{i}\", recall_per_class[i])\n",
    "        mlflow.log_metric(f\"f1_class_{i}\", f1_per_class[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ML\\MLenv\\lib\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:166: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import cloudpickle\n",
    "\n",
    "class CustomLogisticWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, trained_model):\n",
    "        self.trained_model = trained_model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "\n",
    "        return self.trained_model.predict(model_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 53.90it/s]\n",
      "2025/04/06 05:15:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run ridge_logistic_run at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594/runs/b0d1ce7e49064921b03ded60bcc986e3\n",
      "🧪 View experiment at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import mlflow.pyfunc\n",
    "import cloudpickle\n",
    "\n",
    "# เริ่ม MLflow run\n",
    "with mlflow.start_run(run_name=\"ridge_logistic_run\", nested=True):\n",
    "    # Log พารามิเตอร์และ metrics\n",
    "    mlflow.log_param(\"model_type\", \"Custom LogisticRegression\")\n",
    "    mlflow.log_param(\"lambda_\", model.lambda_)\n",
    "    mlflow.log_param(\"method\", model.method)\n",
    "    mlflow.log_param(\"alpha\", model.alpha)\n",
    "    mlflow.log_param(\"max_iter\", model.max_iter)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"macro_f1\", f1)\n",
    "\n",
    "    # Log custom model (wrapper + original model)\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        model_path = os.path.join(tmp_dir, \"model.pkl\")\n",
    "        \n",
    "        # Save the trained model using cloudpickle\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            cloudpickle.dump(model, f)\n",
    "\n",
    "        # Log the model using the wrapper\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            python_model=CustomLogisticWrapper(model),\n",
    "            artifacts={\"model_file\": model_path}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/06 05:15:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run ridge_logistic_run at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594/runs/155b2de0cad54cdd914b4ab0c09b20d0\n",
      "🧪 View experiment at: https://mlflow.ml.brain.cs.ait.ac.th/#/experiments/439733742680906594\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# เริ่มต้น MLflow run\n",
    "with mlflow.start_run(run_name=\"ridge_logistic_run\", nested=True):\n",
    "    # Log พารามิเตอร์ต่างๆ\n",
    "    mlflow.log_param(\"model_type\", \"Custom LogisticRegression\")\n",
    "    mlflow.log_param(\"lambda_\", model.lambda_)  # ถ้ามี\n",
    "    mlflow.log_param(\"alpha\", model.alpha)  # ถ้ามี\n",
    "    mlflow.log_param(\"max_iter\", model.max_iter)  # ถ้ามี\n",
    "    \n",
    "    # Log metrics เช่น accuracy\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"macro_f1\", f1)\n",
    "\n",
    "    # Log โมเดลด้วย Custom Wrapper\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",  # ระบุที่เก็บโมเดลใน MLflow\n",
    "        python_model=CustomLogisticWrapper(model)  # ส่งโมเดลที่คุณสร้างเอง\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
